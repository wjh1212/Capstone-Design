# part1
▶ 하기의 내용은 edge impulse를 통하여 학습된 결과 및 rp2040에 내장된 마이크와 Arduino ide에서 제공하는 샘플 코드를 이용하여 음성 인식률을 확인하고, 이의 결과를 mqtt를 이용하여 node-red의 DashBoard에서 시각적으로 보여주는 과정이다. 

①	.wav 확장자의 음성 샘플을 저장. 
지난 과정에서 8개의 클래스를 사용하였으나 음성의 명확한 인식을 위하여 Yes(1000개)와 No(1000개), 그리고 생활 소음이나 무음 샘플을 저장한 BackGround(30개)로 클래스를 축약하였음. 
→ 총 2030개의 샘플 데이터를 학습. 

![image](https://github.com/wjh1212/Capstone-Design/assets/103232862/6ceaff67-71f3-477e-890e-c8eadc2bb2fc)

②	 상기의 음성 샘플 파일들을 edge impulse에서 학습.

![image](https://github.com/wjh1212/Capstone-Design/assets/103232862/f1109415-3524-4405-8601-d2ad61799a8a)

→ 특징 탐색 결과

![image](https://github.com/wjh1212/Capstone-Design/assets/103232862/59fc05ad-4f49-42ef-b1db-d566d0acb3b7)

→ 99.6% 우수한 인식 결과를 보여줌.

![image](https://github.com/wjh1212/Capstone-Design/assets/103232862/8cab8a16-f831-41d5-9027-e2010e664b74)

③	학습시킨 음성 샘플을 Arduino ide 라이브러리를 위한 .zip 파일로 추출.

![image](https://github.com/wjh1212/Capstone-Design/assets/103232862/2e3096fe-9677-4f8d-9a07-5dd834979cc3)

④	.zip 파일 라이브러리를 Arduino ide에 추가한 후 rp2040_microphone_continous.ino 샘플 코드를 수행. 

![image](https://github.com/wjh1212/Capstone-Design/assets/103232862/46505fe9-a9c8-475b-b82d-2f6b3fb1c063)
![image](https://github.com/wjh1212/Capstone-Design/assets/103232862/6f0baabf-8080-44ce-bbea-78db8b8c0479)

→ “No”라고 말했을 때 예측 결과가 시리얼 모니터에서 정상적으로 출력되는 모습. 

⑤	Mqtt 통신을 통해 Arduino ide에서 출력되는 음성 인식 결과와 해당 결과의 레이블 번호를 node-red에 송신함. 송신되는 결과에 따라 text 노드와 gauge 노드를 이용하여 시각적으로 보여줌. 

![image](https://github.com/wjh1212/Capstone-Design/assets/103232862/1e8a9f77-3e6b-4bf5-9fc6-4127d26ebb6d)
![image](https://github.com/wjh1212/Capstone-Design/assets/103232862/e7ecd526-56a3-4bff-9410-b677499ec9a4)

▶ gauge에 표시되는 수치는 “BackGround”, “No”, “Yes”의 순서대로 0, 1, 2를 나타냄.
▶ 송신되는 음성의 인식 결과에 따라 Voice Result에 해당 결과를 보여줌. 

⑥	Mqtt 통신(파이썬의 paho.mqtt.client 패키지를 이용)을 통해 Part-2에서 얻은 얼굴 인식 결과와 해당 결과의 실시간 영상을 node-red에 송신함. 얼굴이 인식된 결과의 이니셜은 DashBoard의 text 노드를 통해 시각적으로 보여줌. 송신되는 실시간 영상은 image preview 노드를 통해 flow 화면에서 확인이 가능함. 

![image](https://github.com/wjh1212/Capstone-Design/assets/103232862/8238e7fa-68b6-4ed0-8929-74283803254d)

![image](https://github.com/wjh1212/Capstone-Design/assets/103232862/609f9264-6856-49e3-b8ce-87244986069d)

→ 파이썬 코드를 수행한 결과 화면.

![image](https://github.com/wjh1212/Capstone-Design/assets/103232862/38318160-b51e-4767-9ddf-a2c447e782cb)

→ 파이썬에서 실시간으로 수행되는 결과 영상을 mqtt를 통해 송신하고, 이를 node-red의 flow에서 확인이 가능한 모습.

![image](https://github.com/wjh1212/Capstone-Design/assets/103232862/89da4aa3-dd4b-41ca-aeb3-51cfab0efebd)

→ 얼굴 인식의 결과에 따라 해당 내용을 DashBoard에 출력.



# part2

티처블 머신을 사용하여 얼굴을 인식하고 예측도를 측정하였음.

영상 캡쳐 기능을 확인하여 한사람당 대략 200장 정도의 사진을 캡쳐하였음.

티처블 머신 기능을 활용하여 얼굴을 학습시킴.
![캡쳐4](https://github.com/wjh1212/Capstone-Design/assets/103232862/bb19c920-f0f2-441a-86d6-d6f26ddff68b)

그리고 영상처리 코드를 짜서 코드를 실행 시킴.
![캡쳐5](https://github.com/wjh1212/Capstone-Design/assets/103232862/bc454a20-d5bf-4841-b1cc-f7a660843e29)

 다음은 영상처리에 대한 결과임.

![캡쳐1](https://github.com/wjh1212/Capstone-Design/assets/103232862/5bccb113-c6c1-4828-866d-decc491c14bf)



 전부다 85퍼 이상의 확률이 나옴.

![캡쳐2](https://github.com/wjh1212/Capstone-Design/assets/103232862/95e801cb-aaf7-48b4-8413-4e26f79bd660)

이것도 85퍼 이상의 확률이 나옴.

![캡쳐3](https://github.com/wjh1212/Capstone-Design/assets/103232862/5e259914-f8f9-49d6-b21b-4e5e374cff20)

인식되지 않은 사용자가 나오면 unknwon으로 나오게 됨.



# part3

사용기기 : 갤럭시 S22

IDE : Android 스튜디오

사용언어 :　Java

Node-red에서 상황 감지 시 (Yes라고 표시되면) 준비된 Web server(HTTP 또는 HTTPS를 통해 웹 브라우저에서 요청하는 HTML 문서나 오브젝트(이미지 파일 등)을 전송해주는 서비스 프로그램) 로 접속하며 Web server에 있는 PHP 코드가 작동합니다. Google FCM Server를 통해서 Push Message 송신하면 스마트폰 어플리케이션이 Push Message 수신 받아서 지정된 번호로 전화 발신을 해줍니다.


![image](https://github.com/wjh1212/Capstone-Design/assets/103232862/a993913d-8d8a-4a51-adb6-4a83847be658)





part3를 part1과 연결하기 위해 switch, function1, http request 노드를 추가로 연결하였습니다.


①  rp2040에 내장된 PDM 마이크에 yes라고 말했을 때 작동되게 하기 위해 switch노드를 사용하여 yes를 말하였을 때 연결된 http request노드가 작동합니다.

![image](https://github.com/wjh1212/Capstone-Design/assets/103232862/45d118ad-fe79-4b06-9ec2-5eab181d04cd)


② FCM Push Message 송신을 위해 http request 노드를 작성하였습니다. 이 노드를 통해 외부에 있는 별도의 웹 서버에 접속하게 되며, 지정된 경로에 위치한 FCM 푸시 메시지 송신 PHP 코드가 작동하게 됩니다. 
PHP 코드는 해당 주소에 있는 코드를 사용하였습니다. (https://archijude.tistory.com/281)

![image](https://github.com/wjh1212/Capstone-Design/assets/103232862/4d908185-e4d4-41be-85c5-104783ad0fbf)


③ No인 경우에는 아무 기능도, 역할도 없는 fuction 1로 넘겨서 아무 작동도 하지 않도록 하였습니다.


![image](https://github.com/wjh1212/Capstone-Design/assets/103232862/ae049f29-3ba1-4889-ac9b-2795062866ab)




④Google FCM Server를 통해서 Push Message 송신하면 스마트폰 어플리케이션이 Push Message 수신 받아서 지정된 번호로 전화 발신을 해줍니다.


# Part1, 2, 3 통합본
- 영상을 통해 최종 결과를 확인. 
